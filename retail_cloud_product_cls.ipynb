{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "retail_cloud_product_cls.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1Rj2oDhEZuyp4GS47RMm_tk0qeBbaLBKo",
      "authorship_tag": "ABX9TyM+OThFdP3R+kttjRRviOpd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ICM-AI/retail_cloud/blob/main/retail_cloud_product_cls.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "SPXTInCprI1o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0095a3b5-1376-4dd6-f423-231b05a10291"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting paddlehub\n",
            "  Downloading paddlehub-2.2.0-py3-none-any.whl (212 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▌                              | 10 kB 21.2 MB/s eta 0:00:01\r\u001b[K     |███                             | 20 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 30 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 40 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 51 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 61 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 71 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 81 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 92 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 102 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 112 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 122 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 133 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 143 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 153 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 163 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 174 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 184 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 194 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 204 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 212 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyzmq in /usr/local/lib/python3.7/dist-packages (from paddlehub) (22.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from paddlehub) (1.21.5)\n",
            "Collecting paddlenlp>=2.0.0\n",
            "  Downloading paddlenlp-2.2.5-py3-none-any.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 43.5 MB/s \n",
            "\u001b[?25hCollecting rarfile\n",
            "  Downloading rarfile-4.0-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from paddlehub) (4.63.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from paddlehub) (3.2.2)\n",
            "Collecting visualdl>=2.0.0\n",
            "  Downloading visualdl-2.2.3-py3-none-any.whl (2.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.7 MB 37.0 MB/s \n",
            "\u001b[?25hCollecting gunicorn>=19.10.0\n",
            "  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 7.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from paddlehub) (3.6.0)\n",
            "Requirement already satisfied: flask>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from paddlehub) (1.1.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from paddlehub) (7.1.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from paddlehub) (3.13)\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.7/dist-packages (from paddlehub) (1.9)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from paddlehub) (4.1.2.30)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from paddlehub) (21.3)\n",
            "Collecting paddle2onnx>=0.5.1\n",
            "  Downloading paddle2onnx-0.9.2-py3-none-any.whl (100 kB)\n",
            "\u001b[K     |████████████████████████████████| 100 kB 10.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask>=1.1.0->paddlehub) (7.1.2)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask>=1.1.0->paddlehub) (2.11.3)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from flask>=1.1.0->paddlehub) (1.0.1)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask>=1.1.0->paddlehub) (1.1.0)\n",
            "Requirement already satisfied: setuptools>=3.0 in /usr/local/lib/python3.7/dist-packages (from gunicorn>=19.10.0->paddlehub) (57.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->flask>=1.1.0->paddlehub) (2.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from paddle2onnx>=0.5.1->paddlehub) (1.15.0)\n",
            "Collecting onnx<=1.9.0\n",
            "  Downloading onnx-1.9.0-cp37-cp37m-manylinux2010_x86_64.whl (12.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.2 MB 33.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from paddle2onnx>=0.5.1->paddlehub) (3.17.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx<=1.9.0->paddle2onnx>=0.5.1->paddlehub) (3.10.0.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from paddlenlp>=2.0.0->paddlehub) (3.1.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from paddlenlp>=2.0.0->paddlehub) (0.70.12.2)\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.0.0-py3-none-any.whl (325 kB)\n",
            "\u001b[K     |████████████████████████████████| 325 kB 47.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jieba in /usr/local/lib/python3.7/dist-packages (from paddlenlp>=2.0.0->paddlehub) (0.42.1)\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 2.0 MB/s \n",
            "\u001b[?25hCollecting shellcheck-py\n",
            "  Downloading shellcheck_py-0.8.0.4-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 34.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from visualdl>=2.0.0->paddlehub) (1.3.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from visualdl>=2.0.0->paddlehub) (2.23.0)\n",
            "Collecting bce-python-sdk\n",
            "  Downloading bce-python-sdk-0.8.64.tar.gz (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 46.5 MB/s \n",
            "\u001b[?25hCollecting Flask-Babel>=1.0.0\n",
            "  Downloading Flask_Babel-2.0.0-py3-none-any.whl (9.3 kB)\n",
            "Collecting flake8>=3.7.9\n",
            "  Downloading flake8-4.0.1-py2.py3-none-any.whl (64 kB)\n",
            "\u001b[K     |████████████████████████████████| 64 kB 2.7 MB/s \n",
            "\u001b[?25hCollecting pre-commit\n",
            "  Downloading pre_commit-2.17.0-py2.py3-none-any.whl (195 kB)\n",
            "\u001b[K     |████████████████████████████████| 195 kB 49.9 MB/s \n",
            "\u001b[?25hCollecting pycodestyle<2.9.0,>=2.8.0\n",
            "  Downloading pycodestyle-2.8.0-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 908 kB/s \n",
            "\u001b[?25hCollecting pyflakes<2.5.0,>=2.4.0\n",
            "  Downloading pyflakes-2.4.0-py2.py3-none-any.whl (69 kB)\n",
            "\u001b[K     |████████████████████████████████| 69 kB 7.1 MB/s \n",
            "\u001b[?25hCollecting importlib-metadata<4.3\n",
            "  Downloading importlib_metadata-4.2.0-py3-none-any.whl (16 kB)\n",
            "Collecting mccabe<0.7.0,>=0.6.0\n",
            "  Downloading mccabe-0.6.1-py2.py3-none-any.whl (8.6 kB)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from Flask-Babel>=1.0.0->visualdl>=2.0.0->paddlehub) (2018.9)\n",
            "Requirement already satisfied: Babel>=2.3 in /usr/local/lib/python3.7/dist-packages (from Flask-Babel>=1.0.0->visualdl>=2.0.0->paddlehub) (2.9.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.3->flake8>=3.7.9->visualdl>=2.0.0->paddlehub) (3.7.0)\n",
            "Collecting pycryptodome>=3.8.0\n",
            "  Downloading pycryptodome-3.14.1-cp35-abi3-manylinux2010_x86_64.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 37.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: future>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from bce-python-sdk->visualdl>=2.0.0->paddlehub) (0.16.0)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 50.0 MB/s \n",
            "\u001b[?25hCollecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2022.2.0-py3-none-any.whl (134 kB)\n",
            "\u001b[K     |████████████████████████████████| 134 kB 50.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets->paddlenlp>=2.0.0->paddlehub) (0.3.4)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets->paddlenlp>=2.0.0->paddlehub) (6.0.1)\n",
            "Collecting huggingface-hub<1.0.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 5.3 MB/s \n",
            "\u001b[?25hCollecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 39.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->paddlehub) (3.0.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->visualdl>=2.0.0->paddlehub) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->visualdl>=2.0.0->paddlehub) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->visualdl>=2.0.0->paddlehub) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->visualdl>=2.0.0->paddlehub) (1.24.3)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 50.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->paddlenlp>=2.0.0->paddlehub) (21.4.0)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 3.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->paddlenlp>=2.0.0->paddlehub) (2.0.12)\n",
            "Collecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 35.0 MB/s \n",
            "\u001b[?25hCollecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 47.9 MB/s \n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->paddlenlp>=2.0.0->paddlehub) (1.5.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->paddlehub) (1.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->paddlehub) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->paddlehub) (0.11.0)\n",
            "Collecting toml\n",
            "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
            "Collecting virtualenv>=20.0.8\n",
            "  Downloading virtualenv-20.14.0-py2.py3-none-any.whl (8.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8 MB 30.8 MB/s \n",
            "\u001b[?25hCollecting identify>=1.0.0\n",
            "  Downloading identify-2.4.12-py2.py3-none-any.whl (98 kB)\n",
            "\u001b[K     |████████████████████████████████| 98 kB 7.4 MB/s \n",
            "\u001b[?25hCollecting nodeenv>=0.11.1\n",
            "  Downloading nodeenv-1.6.0-py2.py3-none-any.whl (21 kB)\n",
            "Collecting pyyaml\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 34.4 MB/s \n",
            "\u001b[?25hCollecting cfgv>=2.0.0\n",
            "  Downloading cfgv-3.3.1-py2.py3-none-any.whl (7.3 kB)\n",
            "Collecting platformdirs<3,>=2\n",
            "  Downloading platformdirs-2.5.1-py3-none-any.whl (14 kB)\n",
            "Collecting distlib<1,>=0.3.1\n",
            "  Downloading distlib-0.3.4-py2.py3-none-any.whl (461 kB)\n",
            "\u001b[K     |████████████████████████████████| 461 kB 42.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->paddlenlp>=2.0.0->paddlehub) (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp>=2.0.0->paddlehub) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp>=2.0.0->paddlehub) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp>=2.0.0->paddlehub) (3.1.0)\n",
            "Building wheels for collected packages: bce-python-sdk, seqeval\n",
            "  Building wheel for bce-python-sdk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bce-python-sdk: filename=bce_python_sdk-0.8.64-py3-none-any.whl size=202973 sha256=04a756dc9a638ff8c41e0248d483c3af4646ed0192e317ab76067c5ad15fe51f\n",
            "  Stored in directory: /root/.cache/pip/wheels/fd/ee/a5/4ad3bdc0e60b48e892e8bd6f661a3201d7e76dccfa9e968b34\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=0987fca268835dd73fd77715b202fd0197b24b16137768cfcca96f1842376c07\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "Successfully built bce-python-sdk seqeval\n",
            "Installing collected packages: multidict, frozenlist, yarl, urllib3, asynctest, async-timeout, aiosignal, pyyaml, platformdirs, importlib-metadata, fsspec, distlib, aiohttp, xxhash, virtualenv, toml, responses, pyflakes, pycryptodome, pycodestyle, nodeenv, mccabe, identify, huggingface-hub, cfgv, shellcheck-py, seqeval, pre-commit, onnx, Flask-Babel, flake8, datasets, colorlog, colorama, bce-python-sdk, visualdl, rarfile, paddlenlp, paddle2onnx, gunicorn, paddlehub\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 4.11.3\n",
            "    Uninstalling importlib-metadata-4.11.3:\n",
            "      Successfully uninstalled importlib-metadata-4.11.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "markdown 3.3.6 requires importlib-metadata>=4.4; python_version < \"3.10\", but you have importlib-metadata 4.2.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed Flask-Babel-2.0.0 aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 bce-python-sdk-0.8.64 cfgv-3.3.1 colorama-0.4.4 colorlog-6.6.0 datasets-2.0.0 distlib-0.3.4 flake8-4.0.1 frozenlist-1.3.0 fsspec-2022.2.0 gunicorn-20.1.0 huggingface-hub-0.4.0 identify-2.4.12 importlib-metadata-4.2.0 mccabe-0.6.1 multidict-6.0.2 nodeenv-1.6.0 onnx-1.9.0 paddle2onnx-0.9.2 paddlehub-2.2.0 paddlenlp-2.2.5 platformdirs-2.5.1 pre-commit-2.17.0 pycodestyle-2.8.0 pycryptodome-3.14.1 pyflakes-2.4.0 pyyaml-6.0 rarfile-4.0 responses-0.18.0 seqeval-1.2.2 shellcheck-py-0.8.0.4 toml-0.10.2 urllib3-1.25.11 virtualenv-20.14.0 visualdl-2.2.3 xxhash-3.0.0 yarl-1.7.2\n",
            "Collecting paddlepaddle-gpu\n",
            "  Downloading paddlepaddle_gpu-2.2.2-cp37-cp37m-manylinux1_x86_64.whl (435.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 435.4 MB 30 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13 in /usr/local/lib/python3.7/dist-packages (from paddlepaddle-gpu) (1.21.5)\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.7/dist-packages (from paddlepaddle-gpu) (0.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from paddlepaddle-gpu) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from paddlepaddle-gpu) (3.17.3)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from paddlepaddle-gpu) (2.23.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from paddlepaddle-gpu) (7.1.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from paddlepaddle-gpu) (4.4.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->paddlepaddle-gpu) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->paddlepaddle-gpu) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->paddlepaddle-gpu) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->paddlepaddle-gpu) (2021.10.8)\n",
            "Installing collected packages: paddlepaddle-gpu\n",
            "Successfully installed paddlepaddle-gpu-2.2.2\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade paddlehub\n",
        "!pip install --upgrade paddlepaddle-gpu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import time\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from matplotlib.pyplot import MultipleLocator\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import paddle\n",
        "import paddlehub as hub\n",
        "from paddlehub.datasets.base_nlp_dataset import TextClassificationDataset\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "tD-TutU9twvI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 挂载 google drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "id": "DBZwFVAXucdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mf_standard_data = pd.read_excel('product_cls_data/mf_data.xlsx')\n",
        "target_list = mf_standard_data['product_category_first_name'].drop_duplicates(\n",
        ").tolist()"
      ],
      "metadata": {
        "id": "4KoV-JI8TvSP"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset(TextClassificationDataset):\n",
        "    # 数据集存放目录\n",
        "    base_path = 'product_cls_data'\n",
        "    # 数据集的标签列表\n",
        "    label_list = target_list\n",
        "\n",
        "    def __init__(self, tokenizer, max_seq_len: int = 128, mode: str = 'train'):\n",
        "        if mode == 'train':\n",
        "            data_file = 'train.txt'\n",
        "        elif mode == 'test':\n",
        "            data_file = 'test.txt'\n",
        "        else:\n",
        "            data_file = 'test.txt'\n",
        "        super().__init__(base_path=self.base_path,\n",
        "                         tokenizer=tokenizer,\n",
        "                         max_seq_len=max_seq_len,\n",
        "                         mode=mode,\n",
        "                         data_file=data_file,\n",
        "                         label_list=self.label_list,\n",
        "                         is_file_with_header=True)\n",
        "\n",
        "\n",
        "# 选择所需要的模型，获取对应的tokenizer\n",
        "model = hub.Module(name='chinese-bert-wwm',\n",
        "                   task='seq-cls',\n",
        "                   num_classes=len(MyDataset.label_list))\n",
        "tokenizer = model.get_tokenizer()\n",
        "\n",
        "# 实例化训练集\n",
        "train_dataset = MyDataset(tokenizer)"
      ],
      "metadata": {
        "id": "ehDC_kl-uwX9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fa98390-b706-46f3-e622-5fe20f7d12d1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[2022-03-26 23:18:00,668] [    INFO]\u001b[0m - Already cached /root/.paddlenlp/models/bert-wwm-chinese/bert-wwm-chinese.pdparams\u001b[0m\n",
            "\u001b[32m[2022-03-26 23:18:02,472] [    INFO]\u001b[0m - Already cached /root/.paddlenlp/models/bert-wwm-chinese/bert-wwm-chinese-vocab.txt\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rain_dataset = MyDataset(tokenizer=tokenizer,\n",
        "                         max_seq_len=128,\n",
        "                         mode='train')\n",
        "test_dataset = MyDataset(tokenizer=tokenizer,\n",
        "                         max_seq_len=128,\n",
        "                         mode='test')\n",
        "dev_dataset = MyDataset(tokenizer=tokenizer,\n",
        "                           max_seq_len=128,\n",
        "                           mode='dev')"
      ],
      "metadata": {
        "id": "l5J3PoGauwi8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0052dabc-db24-4372-836b-4bc608882708"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[2022-03-26 23:18:32,044] [    INFO]\u001b[0m - Already cached /root/.paddlenlp/models/bert-wwm-chinese/bert-wwm-chinese-vocab.txt\u001b[0m\n",
            "\u001b[32m[2022-03-26 23:18:55,753] [    INFO]\u001b[0m - Already cached /root/.paddlenlp/models/bert-wwm-chinese/bert-wwm-chinese-vocab.txt\u001b[0m\n",
            "\u001b[32m[2022-03-26 23:19:01,322] [    INFO]\u001b[0m - Already cached /root/.paddlenlp/models/bert-wwm-chinese/bert-wwm-chinese-vocab.txt\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = paddle.optimizer.Adam(learning_rate=5e-5,\n",
        "                                  parameters=model.parameters())\n",
        "trainer = hub.Trainer(model,\n",
        "                      optimizer,\n",
        "                      use_gpu=True,\n",
        "                      checkpoint_dir='chinese-bert-wwm_product_cls')\n",
        "\n",
        "trainer.train(train_dataset, epochs=3, batch_size=32, eval_dataset=dev_dataset)\n",
        "\n",
        "# 在测试集上评估当前训练模型\n",
        "trainer.evaluate(test_dataset, batch_size=32)"
      ],
      "metadata": {
        "id": "p5-GbFp7uwmA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0789ac8-3a1e-4fff-f7af-dd5c828063d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[33m[2022-03-26 23:21:44,238] [ WARNING]\u001b[0m - PaddleHub model checkpoint not found, start from scratch...\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:21:55,921] [   TRAIN]\u001b[0m - Epoch=1/3, Step=10/2776 loss=2.9935 acc=0.1719 lr=0.000050 step/sec=0.86 | ETA 02:42:07\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:22:07,401] [   TRAIN]\u001b[0m - Epoch=1/3, Step=20/2776 loss=2.7023 acc=0.2687 lr=0.000050 step/sec=0.87 | ETA 02:40:44\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:22:18,914] [   TRAIN]\u001b[0m - Epoch=1/3, Step=30/2776 loss=2.5055 acc=0.3250 lr=0.000050 step/sec=0.87 | ETA 02:40:25\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:22:30,431] [   TRAIN]\u001b[0m - Epoch=1/3, Step=40/2776 loss=2.2168 acc=0.3969 lr=0.000050 step/sec=0.87 | ETA 02:40:16\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:22:42,014] [   TRAIN]\u001b[0m - Epoch=1/3, Step=50/2776 loss=2.2693 acc=0.3563 lr=0.000050 step/sec=0.86 | ETA 02:40:22\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:22:53,591] [   TRAIN]\u001b[0m - Epoch=1/3, Step=60/2776 loss=1.9012 acc=0.5000 lr=0.000050 step/sec=0.86 | ETA 02:40:25\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:23:05,210] [   TRAIN]\u001b[0m - Epoch=1/3, Step=70/2776 loss=1.7348 acc=0.5500 lr=0.000050 step/sec=0.86 | ETA 02:40:33\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:23:16,853] [   TRAIN]\u001b[0m - Epoch=1/3, Step=80/2776 loss=1.5091 acc=0.5750 lr=0.000050 step/sec=0.86 | ETA 02:40:41\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:23:28,480] [   TRAIN]\u001b[0m - Epoch=1/3, Step=90/2776 loss=1.4597 acc=0.6062 lr=0.000050 step/sec=0.86 | ETA 02:40:45\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:23:40,117] [   TRAIN]\u001b[0m - Epoch=1/3, Step=100/2776 loss=1.4122 acc=0.6438 lr=0.000050 step/sec=0.86 | ETA 02:40:50\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:23:51,764] [   TRAIN]\u001b[0m - Epoch=1/3, Step=110/2776 loss=1.1499 acc=0.7063 lr=0.000050 step/sec=0.86 | ETA 02:40:54\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:24:03,361] [   TRAIN]\u001b[0m - Epoch=1/3, Step=120/2776 loss=1.2032 acc=0.6781 lr=0.000050 step/sec=0.86 | ETA 02:40:54\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:24:14,925] [   TRAIN]\u001b[0m - Epoch=1/3, Step=130/2776 loss=1.2154 acc=0.6750 lr=0.000050 step/sec=0.86 | ETA 02:40:53\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:24:26,514] [   TRAIN]\u001b[0m - Epoch=1/3, Step=140/2776 loss=1.2576 acc=0.6312 lr=0.000050 step/sec=0.86 | ETA 02:40:52\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:24:38,109] [   TRAIN]\u001b[0m - Epoch=1/3, Step=150/2776 loss=1.1563 acc=0.7000 lr=0.000050 step/sec=0.86 | ETA 02:40:53\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:24:49,741] [   TRAIN]\u001b[0m - Epoch=1/3, Step=160/2776 loss=0.9922 acc=0.7562 lr=0.000050 step/sec=0.86 | ETA 02:40:55\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:25:01,394] [   TRAIN]\u001b[0m - Epoch=1/3, Step=170/2776 loss=0.9978 acc=0.7031 lr=0.000050 step/sec=0.86 | ETA 02:40:58\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:25:12,987] [   TRAIN]\u001b[0m - Epoch=1/3, Step=180/2776 loss=0.9365 acc=0.7562 lr=0.000050 step/sec=0.86 | ETA 02:40:58\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:25:24,532] [   TRAIN]\u001b[0m - Epoch=1/3, Step=190/2776 loss=1.1006 acc=0.7094 lr=0.000050 step/sec=0.87 | ETA 02:40:55\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:25:36,123] [   TRAIN]\u001b[0m - Epoch=1/3, Step=200/2776 loss=1.0538 acc=0.7000 lr=0.000050 step/sec=0.86 | ETA 02:40:55\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:25:47,744] [   TRAIN]\u001b[0m - Epoch=1/3, Step=210/2776 loss=0.8880 acc=0.7500 lr=0.000050 step/sec=0.86 | ETA 02:40:56\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:25:59,386] [   TRAIN]\u001b[0m - Epoch=1/3, Step=220/2776 loss=0.9730 acc=0.7125 lr=0.000050 step/sec=0.86 | ETA 02:40:58\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:26:11,015] [   TRAIN]\u001b[0m - Epoch=1/3, Step=230/2776 loss=0.9172 acc=0.7500 lr=0.000050 step/sec=0.86 | ETA 02:40:59\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:26:22,632] [   TRAIN]\u001b[0m - Epoch=1/3, Step=240/2776 loss=0.9899 acc=0.7250 lr=0.000050 step/sec=0.86 | ETA 02:41:00\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:26:34,223] [   TRAIN]\u001b[0m - Epoch=1/3, Step=250/2776 loss=1.0624 acc=0.7031 lr=0.000050 step/sec=0.86 | ETA 02:40:59\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:26:45,808] [   TRAIN]\u001b[0m - Epoch=1/3, Step=260/2776 loss=0.9621 acc=0.7125 lr=0.000050 step/sec=0.86 | ETA 02:40:59\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:26:57,401] [   TRAIN]\u001b[0m - Epoch=1/3, Step=270/2776 loss=0.8414 acc=0.7719 lr=0.000050 step/sec=0.86 | ETA 02:40:59\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:27:09,017] [   TRAIN]\u001b[0m - Epoch=1/3, Step=280/2776 loss=0.7717 acc=0.7688 lr=0.000050 step/sec=0.86 | ETA 02:40:59\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:27:20,605] [   TRAIN]\u001b[0m - Epoch=1/3, Step=290/2776 loss=0.8946 acc=0.7250 lr=0.000050 step/sec=0.86 | ETA 02:40:59\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:27:32,158] [   TRAIN]\u001b[0m - Epoch=1/3, Step=300/2776 loss=0.7972 acc=0.7656 lr=0.000050 step/sec=0.87 | ETA 02:40:58\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:27:43,718] [   TRAIN]\u001b[0m - Epoch=1/3, Step=310/2776 loss=0.7725 acc=0.7906 lr=0.000050 step/sec=0.87 | ETA 02:40:57\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:27:55,357] [   TRAIN]\u001b[0m - Epoch=1/3, Step=320/2776 loss=0.8547 acc=0.7438 lr=0.000050 step/sec=0.86 | ETA 02:40:58\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:28:07,017] [   TRAIN]\u001b[0m - Epoch=1/3, Step=330/2776 loss=0.8502 acc=0.7562 lr=0.000050 step/sec=0.86 | ETA 02:40:59\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:28:18,677] [   TRAIN]\u001b[0m - Epoch=1/3, Step=340/2776 loss=0.8727 acc=0.7500 lr=0.000050 step/sec=0.86 | ETA 02:41:01\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:28:30,251] [   TRAIN]\u001b[0m - Epoch=1/3, Step=350/2776 loss=0.7652 acc=0.7688 lr=0.000050 step/sec=0.86 | ETA 02:41:00\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:28:41,827] [   TRAIN]\u001b[0m - Epoch=1/3, Step=360/2776 loss=0.6512 acc=0.8156 lr=0.000050 step/sec=0.86 | ETA 02:41:00\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:28:53,405] [   TRAIN]\u001b[0m - Epoch=1/3, Step=370/2776 loss=0.6515 acc=0.8438 lr=0.000050 step/sec=0.86 | ETA 02:40:59\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:29:05,016] [   TRAIN]\u001b[0m - Epoch=1/3, Step=380/2776 loss=0.8634 acc=0.7375 lr=0.000050 step/sec=0.86 | ETA 02:40:59\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:29:16,621] [   TRAIN]\u001b[0m - Epoch=1/3, Step=390/2776 loss=0.6941 acc=0.7812 lr=0.000050 step/sec=0.86 | ETA 02:41:00\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:29:28,218] [   TRAIN]\u001b[0m - Epoch=1/3, Step=400/2776 loss=0.6092 acc=0.8187 lr=0.000050 step/sec=0.86 | ETA 02:41:00\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:29:39,777] [   TRAIN]\u001b[0m - Epoch=1/3, Step=410/2776 loss=0.6241 acc=0.8375 lr=0.000050 step/sec=0.87 | ETA 02:40:59\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:29:51,325] [   TRAIN]\u001b[0m - Epoch=1/3, Step=420/2776 loss=0.7713 acc=0.7875 lr=0.000050 step/sec=0.87 | ETA 02:40:58\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:30:02,929] [   TRAIN]\u001b[0m - Epoch=1/3, Step=430/2776 loss=0.8432 acc=0.7531 lr=0.000050 step/sec=0.86 | ETA 02:40:58\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:30:14,489] [   TRAIN]\u001b[0m - Epoch=1/3, Step=440/2776 loss=0.7943 acc=0.7688 lr=0.000050 step/sec=0.87 | ETA 02:40:57\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:30:26,111] [   TRAIN]\u001b[0m - Epoch=1/3, Step=450/2776 loss=0.6830 acc=0.8063 lr=0.000050 step/sec=0.86 | ETA 02:40:58\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:30:37,660] [   TRAIN]\u001b[0m - Epoch=1/3, Step=460/2776 loss=0.6395 acc=0.8250 lr=0.000050 step/sec=0.87 | ETA 02:40:57\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:30:49,283] [   TRAIN]\u001b[0m - Epoch=1/3, Step=470/2776 loss=0.7497 acc=0.7719 lr=0.000050 step/sec=0.86 | ETA 02:40:57\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:31:00,880] [   TRAIN]\u001b[0m - Epoch=1/3, Step=480/2776 loss=0.6482 acc=0.8094 lr=0.000050 step/sec=0.86 | ETA 02:40:57\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:31:12,424] [   TRAIN]\u001b[0m - Epoch=1/3, Step=490/2776 loss=0.7472 acc=0.7844 lr=0.000050 step/sec=0.87 | ETA 02:40:56\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:31:24,015] [   TRAIN]\u001b[0m - Epoch=1/3, Step=500/2776 loss=0.6751 acc=0.8094 lr=0.000050 step/sec=0.86 | ETA 02:40:56\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:31:35,584] [   TRAIN]\u001b[0m - Epoch=1/3, Step=510/2776 loss=0.6887 acc=0.7906 lr=0.000050 step/sec=0.86 | ETA 02:40:56\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:31:47,180] [   TRAIN]\u001b[0m - Epoch=1/3, Step=520/2776 loss=0.7942 acc=0.7875 lr=0.000050 step/sec=0.86 | ETA 02:40:56\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:31:58,823] [   TRAIN]\u001b[0m - Epoch=1/3, Step=530/2776 loss=0.8286 acc=0.7500 lr=0.000050 step/sec=0.86 | ETA 02:40:57\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:32:10,428] [   TRAIN]\u001b[0m - Epoch=1/3, Step=540/2776 loss=0.6758 acc=0.8187 lr=0.000050 step/sec=0.86 | ETA 02:40:57\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:32:22,029] [   TRAIN]\u001b[0m - Epoch=1/3, Step=550/2776 loss=0.5703 acc=0.8625 lr=0.000050 step/sec=0.86 | ETA 02:40:57\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:32:33,591] [   TRAIN]\u001b[0m - Epoch=1/3, Step=560/2776 loss=0.6615 acc=0.7656 lr=0.000050 step/sec=0.86 | ETA 02:40:56\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:32:45,181] [   TRAIN]\u001b[0m - Epoch=1/3, Step=570/2776 loss=0.6899 acc=0.7937 lr=0.000050 step/sec=0.86 | ETA 02:40:56\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:32:56,815] [   TRAIN]\u001b[0m - Epoch=1/3, Step=580/2776 loss=0.5736 acc=0.8531 lr=0.000050 step/sec=0.86 | ETA 02:40:57\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:33:08,414] [   TRAIN]\u001b[0m - Epoch=1/3, Step=590/2776 loss=0.6748 acc=0.8156 lr=0.000050 step/sec=0.86 | ETA 02:40:57\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:33:19,970] [   TRAIN]\u001b[0m - Epoch=1/3, Step=600/2776 loss=0.6243 acc=0.8125 lr=0.000050 step/sec=0.87 | ETA 02:40:56\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:33:31,554] [   TRAIN]\u001b[0m - Epoch=1/3, Step=610/2776 loss=0.6080 acc=0.8313 lr=0.000050 step/sec=0.86 | ETA 02:40:56\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:33:43,135] [   TRAIN]\u001b[0m - Epoch=1/3, Step=620/2776 loss=0.7331 acc=0.7906 lr=0.000050 step/sec=0.86 | ETA 02:40:56\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:33:54,779] [   TRAIN]\u001b[0m - Epoch=1/3, Step=630/2776 loss=0.5210 acc=0.8375 lr=0.000050 step/sec=0.86 | ETA 02:40:57\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:34:06,425] [   TRAIN]\u001b[0m - Epoch=1/3, Step=640/2776 loss=0.6725 acc=0.8250 lr=0.000050 step/sec=0.86 | ETA 02:40:57\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:34:18,002] [   TRAIN]\u001b[0m - Epoch=1/3, Step=650/2776 loss=0.6960 acc=0.7844 lr=0.000050 step/sec=0.86 | ETA 02:40:57\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:34:29,618] [   TRAIN]\u001b[0m - Epoch=1/3, Step=660/2776 loss=0.5533 acc=0.8375 lr=0.000050 step/sec=0.86 | ETA 02:40:57\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:34:41,184] [   TRAIN]\u001b[0m - Epoch=1/3, Step=670/2776 loss=0.6074 acc=0.8281 lr=0.000050 step/sec=0.86 | ETA 02:40:57\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:34:52,778] [   TRAIN]\u001b[0m - Epoch=1/3, Step=680/2776 loss=0.5785 acc=0.8281 lr=0.000050 step/sec=0.86 | ETA 02:40:57\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:35:04,404] [   TRAIN]\u001b[0m - Epoch=1/3, Step=690/2776 loss=0.6321 acc=0.8313 lr=0.000050 step/sec=0.86 | ETA 02:40:57\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:35:15,987] [   TRAIN]\u001b[0m - Epoch=1/3, Step=700/2776 loss=0.6522 acc=0.8031 lr=0.000050 step/sec=0.86 | ETA 02:40:57\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:35:27,537] [   TRAIN]\u001b[0m - Epoch=1/3, Step=710/2776 loss=0.6288 acc=0.8156 lr=0.000050 step/sec=0.87 | ETA 02:40:56\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:35:39,096] [   TRAIN]\u001b[0m - Epoch=1/3, Step=720/2776 loss=0.6736 acc=0.7937 lr=0.000050 step/sec=0.87 | ETA 02:40:56\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:35:50,733] [   TRAIN]\u001b[0m - Epoch=1/3, Step=730/2776 loss=0.6177 acc=0.8094 lr=0.000050 step/sec=0.86 | ETA 02:40:56\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:36:02,344] [   TRAIN]\u001b[0m - Epoch=1/3, Step=740/2776 loss=0.4977 acc=0.8531 lr=0.000050 step/sec=0.86 | ETA 02:40:57\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:36:13,934] [   TRAIN]\u001b[0m - Epoch=1/3, Step=750/2776 loss=0.5408 acc=0.8438 lr=0.000050 step/sec=0.86 | ETA 02:40:57\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:36:25,522] [   TRAIN]\u001b[0m - Epoch=1/3, Step=760/2776 loss=0.5448 acc=0.8219 lr=0.000050 step/sec=0.86 | ETA 02:40:56\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:36:37,079] [   TRAIN]\u001b[0m - Epoch=1/3, Step=770/2776 loss=0.5687 acc=0.8094 lr=0.000050 step/sec=0.87 | ETA 02:40:56\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:36:48,657] [   TRAIN]\u001b[0m - Epoch=1/3, Step=780/2776 loss=0.5133 acc=0.8281 lr=0.000050 step/sec=0.86 | ETA 02:40:56\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:37:00,289] [   TRAIN]\u001b[0m - Epoch=1/3, Step=790/2776 loss=0.6007 acc=0.8187 lr=0.000050 step/sec=0.86 | ETA 02:40:56\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:37:11,916] [   TRAIN]\u001b[0m - Epoch=1/3, Step=800/2776 loss=0.5571 acc=0.8219 lr=0.000050 step/sec=0.86 | ETA 02:40:57\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:37:23,464] [   TRAIN]\u001b[0m - Epoch=1/3, Step=810/2776 loss=0.5693 acc=0.8219 lr=0.000050 step/sec=0.87 | ETA 02:40:56\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:37:34,994] [   TRAIN]\u001b[0m - Epoch=1/3, Step=820/2776 loss=0.6030 acc=0.8281 lr=0.000050 step/sec=0.87 | ETA 02:40:55\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:37:46,593] [   TRAIN]\u001b[0m - Epoch=1/3, Step=830/2776 loss=0.5315 acc=0.8313 lr=0.000050 step/sec=0.86 | ETA 02:40:55\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:37:58,185] [   TRAIN]\u001b[0m - Epoch=1/3, Step=840/2776 loss=0.4872 acc=0.8844 lr=0.000050 step/sec=0.86 | ETA 02:40:55\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:38:09,772] [   TRAIN]\u001b[0m - Epoch=1/3, Step=850/2776 loss=0.4550 acc=0.8656 lr=0.000050 step/sec=0.86 | ETA 02:40:55\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:38:21,335] [   TRAIN]\u001b[0m - Epoch=1/3, Step=860/2776 loss=0.5168 acc=0.8313 lr=0.000050 step/sec=0.86 | ETA 02:40:55\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:38:32,909] [   TRAIN]\u001b[0m - Epoch=1/3, Step=870/2776 loss=0.5478 acc=0.8375 lr=0.000050 step/sec=0.86 | ETA 02:40:55\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:38:44,503] [   TRAIN]\u001b[0m - Epoch=1/3, Step=880/2776 loss=0.5604 acc=0.8281 lr=0.000050 step/sec=0.86 | ETA 02:40:55\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:38:56,110] [   TRAIN]\u001b[0m - Epoch=1/3, Step=890/2776 loss=0.5501 acc=0.8375 lr=0.000050 step/sec=0.86 | ETA 02:40:55\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:39:07,666] [   TRAIN]\u001b[0m - Epoch=1/3, Step=900/2776 loss=0.4319 acc=0.8719 lr=0.000050 step/sec=0.87 | ETA 02:40:55\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:39:19,236] [   TRAIN]\u001b[0m - Epoch=1/3, Step=910/2776 loss=0.4994 acc=0.8375 lr=0.000050 step/sec=0.86 | ETA 02:40:54\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:39:30,807] [   TRAIN]\u001b[0m - Epoch=1/3, Step=920/2776 loss=0.5912 acc=0.8187 lr=0.000050 step/sec=0.86 | ETA 02:40:54\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:39:42,404] [   TRAIN]\u001b[0m - Epoch=1/3, Step=930/2776 loss=0.5300 acc=0.8656 lr=0.000050 step/sec=0.86 | ETA 02:40:54\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:39:54,042] [   TRAIN]\u001b[0m - Epoch=1/3, Step=940/2776 loss=0.4956 acc=0.8406 lr=0.000050 step/sec=0.86 | ETA 02:40:55\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:40:05,644] [   TRAIN]\u001b[0m - Epoch=1/3, Step=950/2776 loss=0.5408 acc=0.8406 lr=0.000050 step/sec=0.86 | ETA 02:40:55\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:40:17,240] [   TRAIN]\u001b[0m - Epoch=1/3, Step=960/2776 loss=0.5190 acc=0.8406 lr=0.000050 step/sec=0.86 | ETA 02:40:55\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:40:28,814] [   TRAIN]\u001b[0m - Epoch=1/3, Step=970/2776 loss=0.4692 acc=0.8531 lr=0.000050 step/sec=0.86 | ETA 02:40:55\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:40:40,271] [   TRAIN]\u001b[0m - Epoch=1/3, Step=980/2776 loss=0.5297 acc=0.8594 lr=0.000050 step/sec=0.87 | ETA 02:40:53\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:40:51,712] [   TRAIN]\u001b[0m - Epoch=1/3, Step=990/2776 loss=0.6011 acc=0.8156 lr=0.000050 step/sec=0.87 | ETA 02:40:52\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:41:03,194] [   TRAIN]\u001b[0m - Epoch=1/3, Step=1000/2776 loss=0.5518 acc=0.8469 lr=0.000050 step/sec=0.87 | ETA 02:40:51\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:41:14,720] [   TRAIN]\u001b[0m - Epoch=1/3, Step=1010/2776 loss=0.4443 acc=0.8688 lr=0.000050 step/sec=0.87 | ETA 02:40:51\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:41:26,265] [   TRAIN]\u001b[0m - Epoch=1/3, Step=1020/2776 loss=0.5467 acc=0.8313 lr=0.000050 step/sec=0.87 | ETA 02:40:50\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:41:37,869] [   TRAIN]\u001b[0m - Epoch=1/3, Step=1030/2776 loss=0.5337 acc=0.8438 lr=0.000050 step/sec=0.86 | ETA 02:40:51\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:41:49,491] [   TRAIN]\u001b[0m - Epoch=1/3, Step=1040/2776 loss=0.4166 acc=0.8719 lr=0.000050 step/sec=0.86 | ETA 02:40:51\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:42:01,123] [   TRAIN]\u001b[0m - Epoch=1/3, Step=1050/2776 loss=0.4971 acc=0.8531 lr=0.000050 step/sec=0.86 | ETA 02:40:51\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:42:12,743] [   TRAIN]\u001b[0m - Epoch=1/3, Step=1060/2776 loss=0.5406 acc=0.8281 lr=0.000050 step/sec=0.86 | ETA 02:40:51\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:42:24,365] [   TRAIN]\u001b[0m - Epoch=1/3, Step=1070/2776 loss=0.4775 acc=0.8562 lr=0.000050 step/sec=0.86 | ETA 02:40:52\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:42:35,973] [   TRAIN]\u001b[0m - Epoch=1/3, Step=1080/2776 loss=0.5061 acc=0.8625 lr=0.000050 step/sec=0.86 | ETA 02:40:52\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:42:47,579] [   TRAIN]\u001b[0m - Epoch=1/3, Step=1090/2776 loss=0.5050 acc=0.8531 lr=0.000050 step/sec=0.86 | ETA 02:40:52\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:42:59,201] [   TRAIN]\u001b[0m - Epoch=1/3, Step=1100/2776 loss=0.4607 acc=0.8562 lr=0.000050 step/sec=0.86 | ETA 02:40:52\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:43:10,794] [   TRAIN]\u001b[0m - Epoch=1/3, Step=1110/2776 loss=0.4689 acc=0.8438 lr=0.000050 step/sec=0.86 | ETA 02:40:52\u001b[0m\n",
            "\u001b[36m[2022-03-26 23:43:22,402] [   TRAIN]\u001b[0m - Epoch=1/3, Step=1120/2776 loss=0.4350 acc=0.8688 lr=0.000050 step/sec=0.86 | ETA 02:40:52\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qKv2y7eRuwoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ETcBSaJ-uwrD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}